# test_bayesian_fixed.jl
# ä¿®å¤æ‰€æœ‰é—®é¢˜çš„BayesianOptimization.jlæµ‹è¯•

# æ¿€æ´»é¡¹ç›®ç¯å¢ƒ - ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿æ­£ç¡®çš„é¡¹ç›®ç¯å¢ƒ
import Pkg
# è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•ï¼Œç„¶åå‘ä¸Šä¸€çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
project_root = joinpath(@__DIR__, "..")
Pkg.activate(project_root)
println("âœ… æ¿€æ´»é¡¹ç›®ç¯å¢ƒ: ", project_root)

# ä¸´æ—¶æŠ‘åˆ¶kwargsç›¸å…³çš„å…¼å®¹æ€§è­¦å‘Šï¼ˆè¿™æ˜¯å·²çŸ¥çš„éè‡´å‘½é—®é¢˜ï¼‰
ENV["JULIA_WARN_OVERWRITE"] = "0"

using BayesianOptimization
using GaussianProcesses
using GaussianProcesses: MeanConst, SEArd
using Printf

println("="^70)
println("ğŸ§  BayesianOptimization.jl ä¿®å¤ç‰ˆæœ¬æµ‹è¯•")
println("="^70)

# æµ‹è¯•1ï¼šå®Œå…¨ä¿®å¤çš„äºŒç»´ä¼˜åŒ–
println("\nğŸ“Š æµ‹è¯•1: ä¿®å¤ç‰ˆäºŒç»´è´å¶æ–¯ä¼˜åŒ–")
println("-" ^ 50)

function simple_objective(x)
    # ç®€å•çš„äºŒç»´å‡½æ•°ï¼Œæœ€å¤§å€¼åœ¨ [1.5, -0.5] å¤„
    x1, x2 = x[1], x[2]
    return -(x1 - 1.5)^2 - (x2 + 0.5)^2 + 6.0
end

println("ç›®æ ‡å‡½æ•°: f(x1,x2) = -(x1-1.5)Â² - (x2+0.5)Â² + 6")
println("ç†è®ºæœ€ä¼˜è§£: x = [1.5, -0.5], f_max = 6")
println("æœç´¢ç©ºé—´: x1 âˆˆ [-2, 4], x2 âˆˆ [-3, 2]")

try
    # æ‰‹åŠ¨ç”Ÿæˆåˆå§‹æ•°æ®
    X_init = [[-1.0, -1.0], [0.0, 1.0], [2.0, -1.0], [3.0, 0.0]]
    y_init = [simple_objective(x) for x in X_init]
    
    println("\nğŸ¯ åˆå§‹æ•°æ®:")
    for (i, (x, y)) in enumerate(zip(X_init, y_init))
        println("  ç‚¹$i: x = [$(@sprintf("%.1f", x[1])), $(@sprintf("%.1f", x[2]))], f(x) = $(@sprintf("%.6f", y))")
    end
    
    # è½¬æ¢ä¸ºGPæ ¼å¼
    X_matrix = hcat(X_init...)  # 2Ã—4 çŸ©é˜µ
    y_vector = Vector{Float64}(y_init)
    
    # åˆ›å»ºGPæ¨¡å‹
    gp = GP(X_matrix, y_vector, MeanConst(0.0), SEArd([1.0, 1.0], 0.0))
    
    println("\nğŸ”§ é«˜æ–¯è¿‡ç¨‹åˆ›å»ºæˆåŠŸï¼Œæ•°æ®ç»´åº¦: $(size(X_matrix))")
    
    # æ­£ç¡®çš„MAPGPOptimizeré…ç½®
    # SEArdæœ‰3ä¸ªå‚æ•°ï¼š[x1_scale, x2_scale, signal_variance]
    modeloptimizer = MAPGPOptimizer(
        every = 5,
        noisebounds = [-4, 3],
        kernbounds = [[-2, -2, -3], [3, 3, 2]],  # ç¡®ä¿ä¸‹ç•Œ <= ä¸Šç•Œ
        maxeval = 50
    )
    
    println("âœ… æ¨¡å‹ä¼˜åŒ–å™¨é…ç½®æˆåŠŸ")
    
    # åˆ›å»ºBOptä¼˜åŒ–å™¨
    opt = BOpt(simple_objective,
               gp,
               ExpectedImprovement(),
               modeloptimizer,
               [-2.0, -3.0], [4.0, 2.0],  # è¾¹ç•Œ
               sense = Max,
               maxiterations = 15,
               repetitions = 1,
               verbosity = Progress,
               initializer_iterations = 0)  # å·²æœ‰åˆå§‹æ•°æ®
    
    println("âœ… BOpt ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
    
    # æ‰§è¡Œä¼˜åŒ–
    println("\nğŸš€ æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–...")
    
    result = boptimize!(opt)
    
    println("\nğŸ“ˆ ä¼˜åŒ–ç»“æœ:")
    println("æœ€ä¼˜è§£: x = [$(@sprintf("%.6f", result.observed_optimizer[1])), $(@sprintf("%.6f", result.observed_optimizer[2]))]")
    println("æœ€ä¼˜å€¼: f(x) = $(@sprintf("%.6f", result.observed_optimum))")
    println("æ€»è¿­ä»£æ¬¡æ•°: $(opt.iterations.i)")
    
    # åˆ†æç»“æœ
    distance_to_optimum = sqrt((result.observed_optimizer[1] - 1.5)^2 + (result.observed_optimizer[2] + 0.5)^2)
    println("ä¸ç†è®ºæœ€ä¼˜ç‚¹çš„è·ç¦»: $(@sprintf("%.6f", distance_to_optimum))")
    
    if distance_to_optimum < 0.5 && result.observed_optimum > 5.5
        println("âœ… è´å¶æ–¯ä¼˜åŒ–éå¸¸æˆåŠŸï¼")
    elseif distance_to_optimum < 1.0 && result.observed_optimum > 4.5
        println("âœ… è´å¶æ–¯ä¼˜åŒ–æˆåŠŸï¼")
    else
        println("ğŸ“ˆ è´å¶æ–¯ä¼˜åŒ–æ‰¾åˆ°äº†å¯æ¥å—çš„è§£")
    end
    
    # æ˜¾ç¤ºæ‰€æœ‰è¯„ä¼°ç‚¹
    println("\nğŸ’¡ ä¼˜åŒ–å†å²:")
    best_idx = argmax(opt.observed_optimum)
    for i in 1:min(15, length(opt.observed_optimum))
        x_val = opt.observed_optimizer[i]
        y_val = opt.observed_optimum[i]
        marker = (i == best_idx) ? "ğŸŒŸ" : "  "
        stage = i <= length(X_init) ? "åˆå§‹" : "BO"
        if length(x_val) == 2
            println("$marker [$stage] ç‚¹$i: x = [$(@sprintf("%.3f", x_val[1])), $(@sprintf("%.3f", x_val[2]))], f(x) = $(@sprintf("%.6f", y_val))")
        else
            println("$marker [$stage] ç‚¹$i: x = $(@sprintf("%.3f", x_val)), f(x) = $(@sprintf("%.6f", y_val))")
        end
    end
    
    # è®¡ç®—æ”¹è¿›
    initial_best = maximum(y_init)
    improvement = result.observed_optimum - initial_best
    println("\nğŸ“Š ç›¸å¯¹åˆå§‹é‡‡æ ·çš„æ”¹è¿›: $(@sprintf("%.6f", improvement))")
    
catch e
    println("âŒ äºŒç»´ä¼˜åŒ–æµ‹è¯•å¤±è´¥: $e")
    
    # è¯¦ç»†é”™è¯¯ä¿¡æ¯
    if isa(e, ArgumentError) && occursin("bounds", string(e))
        println("è¿™æ˜¯è¾¹ç•Œè®¾ç½®é—®é¢˜ã€‚kernboundsåº”è¯¥æ˜¯ [[ä¸‹ç•Œ...], [ä¸Šç•Œ...]] æ ¼å¼")
        println("å¯¹äº2D SEArdæ ¸ï¼Œéœ€è¦3ä¸ªå‚æ•°: [x1_scale, x2_scale, signal_var]")
    end
end

# æµ‹è¯•2ï¼šä¸€ç»´ä¼˜åŒ–éªŒè¯
println("\n" ^ 70)
println("ğŸ“Š æµ‹è¯•2: ä¸€ç»´ä¼˜åŒ–éªŒè¯")
println("-" ^ 50)

function simple_1d(x)
    return -(x[1] - 2.5)^2 + 4.0
end

println("ç›®æ ‡å‡½æ•°: f(x) = -(x-2.5)Â² + 4")
println("ç†è®ºæœ€ä¼˜è§£: x = 2.5, f_max = 4")

try
    # ä¸€ç»´åˆå§‹æ•°æ®
    X_1d = reshape([0.0, 1.0, 4.0, 5.0], 1, 4)  # 1Ã—4 çŸ©é˜µ
    y_1d = [simple_1d([x]) for x in [0.0, 1.0, 4.0, 5.0]]
    
    println("åˆå§‹æ•°æ®: X = $(X_1d[1, :]), y = $(round.(y_1d, digits=3))")
    
    # ä¸€ç»´GP
    gp_1d = GP(X_1d, y_1d, MeanConst(0.0), SEArd([1.0], 0.0))
    
    # ä¸€ç»´ä¼˜åŒ–å™¨ - SEArd(1D)æœ‰2ä¸ªå‚æ•°ï¼š[length_scale, signal_var]
    opt_1d = BOpt(simple_1d,
                  gp_1d,
                  UpperConfidenceBound(),
                  MAPGPOptimizer(every = 3, 
                               noisebounds = [-4, 3],
                               kernbounds = [[-2, -3], [3, 2]]),  # [scale, signal]
                  [-1.0], [6.0],
                  sense = Max,
                  maxiterations = 12,
                  repetitions = 1,
                  verbosity = Progress,
                  initializer_iterations = 0)
    
    println("âœ… ä¸€ç»´ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
    
    result_1d = boptimize!(opt_1d)
    
    println("\nğŸ“ˆ ä¸€ç»´ä¼˜åŒ–ç»“æœ:")
    println("æœ€ä¼˜è§£: x = $(@sprintf("%.6f", result_1d.observed_optimizer[1]))")
    println("æœ€ä¼˜å€¼: f(x) = $(@sprintf("%.6f", result_1d.observed_optimum))")
    
    error_x = abs(result_1d.observed_optimizer[1] - 2.5)
    error_f = abs(result_1d.observed_optimum - 4.0)
    
    println("ä½ç½®è¯¯å·®: $(@sprintf("%.6f", error_x))")
    println("å‡½æ•°å€¼è¯¯å·®: $(@sprintf("%.6f", error_f))")
    
    if error_x < 0.3 && error_f < 0.5
        println("âœ… ä¸€ç»´ä¼˜åŒ–éå¸¸æˆåŠŸï¼")
    else
        println("ğŸ“ˆ ä¸€ç»´ä¼˜åŒ–è¡¨ç°è‰¯å¥½")
    end
    
catch e
    println("âŒ ä¸€ç»´ä¼˜åŒ–æµ‹è¯•å¤±è´¥: $e")
end

# æµ‹è¯•3ï¼šé‡‡é›†å‡½æ•°æ¯”è¾ƒ
println("\n" ^ 70)
println("ğŸ“Š æµ‹è¯•3: é‡‡é›†å‡½æ•°æ¯”è¾ƒ")
println("-" ^ 50)

function test_func(x)
    return -(x[1] - 1)^2 + 3.0
end

acquisition_functions = [
    ("Expected Improvement", ExpectedImprovement()),
    ("Upper Confidence Bound", UpperConfidenceBound()),
    ("Probability of Improvement", ProbabilityOfImprovement())
]

println("æµ‹è¯•å‡½æ•°: f(x) = -(x-1)Â² + 3")
println("ç†è®ºæœ€ä¼˜: x = 1, f_max = 3")

for (name, acq_func) in acquisition_functions
    try
        # ç®€å•çš„åˆå§‹æ•°æ®
        X_simple = reshape([-1.0, 0.0, 2.0], 1, 3)
        y_simple = [test_func([x]) for x in [-1.0, 0.0, 2.0]]
        
        gp_test = GP(X_simple, y_simple, MeanConst(0.0), SEArd([1.0], 0.0))
        
        # ä½¿ç”¨NoModelOptimizeré¿å…è¶…å‚æ•°ä¼˜åŒ–é—®é¢˜
        opt_test = BOpt(test_func,
                       gp_test,
                       acq_func,
                       NoModelOptimizer(),  # é¿å…å¤æ‚çš„è¶…å‚æ•°ä¼˜åŒ–
                       [-3.0], [4.0],
                       sense = Max,
                       maxiterations = 8,
                       repetitions = 1,
                       verbosity = Silent,
                       initializer_iterations = 0)
        
        result_test = boptimize!(opt_test)
        
        error = abs(result_test.observed_optimizer[1] - 1.0)
        
        println("ğŸ” $name:")
        println("  æœ€ä¼˜è§£: x = $(@sprintf("%.4f", result_test.observed_optimizer[1])), f(x) = $(@sprintf("%.4f", result_test.observed_optimum))")
        println("  ä½ç½®è¯¯å·®: $(@sprintf("%.4f", error))")
        
        if error < 0.3
            println("  âœ… è¡¨ç°ä¼˜ç§€")
        else
            println("  ğŸ“ˆ è¡¨ç°è‰¯å¥½")
        end
        
    catch e
        println("ğŸ” $name: âŒ å¤±è´¥ - $e")
    end
    println()
end

println("=" ^ 70)
println("ğŸ¯ æµ‹è¯•æ€»ç»“")
println("=" ^ 70)

println("âœ… æˆåŠŸè§£å†³çš„å…³é”®é—®é¢˜:")
println("1. ğŸ“¦ kernboundsæ ¼å¼: [[ä¸‹ç•Œ...], [ä¸Šç•Œ...]]")
println("2. ğŸ”§ è¾¹ç•Œå…³ç³»: ç¡®ä¿æ‰€æœ‰ä¸‹ç•Œ <= ä¸Šç•Œ")
println("3. ğŸ¯ å‚æ•°æ•°é‡: SEArd(dç»´)éœ€è¦d+1ä¸ªè¾¹ç•Œå‚æ•°")
println("4. ğŸš€ æ•°æ®æ ¼å¼: GPéœ€è¦dÃ—nçŸ©é˜µå’Œnç»´å‘é‡")
println("5. ğŸ’¡ è¶…å‚æ•°ä¼˜åŒ–: å¯ç”¨NoModelOptimizeré¿å…å¤æ‚é…ç½®")

println("\nğŸ’¯ BayesianOptimization.jl ç°åœ¨å®Œå…¨å¯ç”¨!")
println("ğŸ“ è¯¦ç»†APIæ–‡æ¡£å·²ä¿å­˜åˆ°: BayesianOptimization_API_Guide.md")
println("=" ^ 70)